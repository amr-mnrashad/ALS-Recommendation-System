{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42a935d5-dd5d-408e-b431-38d5681a6ba7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 0. Notes:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "463aec3e-ef7c-4a58-aea2-a606ab5aa353",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "In these notes I am going to explain the thought process behind the following code and the different part that have been performed.\n",
    "\n",
    "1. Loading the data and the libraries, in this section we combine the two tables together, which are 'web navigation' and 'sku details'\n",
    "2. Data Preprocessing, in this section I start figuring out how can we create a score/rate that best describes the user preference regarding a given product.\n",
    "    - The simple way is to just use the product view as the score, where the more the user views a given product, the more he prefers it or interested in it. However, this simplification doesn't really reflect the user's preference and would'nt result a good recommendation system. So few key points have been tackled in this section, where I first broke down the product id, SKU, into parts and I have only used the first and third part of it, which are model and material. The model id has replaced the product id, then I tried checking the material part as well. However, from the looks of it usually one model has one material, so it didn't make sense to include the material in the score/rate equation.\n",
    "    - The second variable I was interested in observing was the cart_adds, as it has much more importance than the product view, since if the user adds the product to cart then it's most likely he is interested in such product/type.\n",
    "    - So now we have three variables: product view, cart adds, color, the other challenge is figuring out how can we combine them together in order to get a meaningful score that describes the user preference. This was done by introducing weights into the equation, where each variable has its own weight.\n",
    "  For starters the product weight is simply one, then we have cart adds, the question that is asked here on average, how many views does a user make to add a product to cart. Then because there's some large outliers, I have decided to take the median as it would be a better representation to the user's behavior generally. The weight of the final variable is a bit complicated. So the idea here is to see on average how many times does a user view a different color when browsing products, and it's around 1.92.\n",
    "    - The color score was calculated by giving importance to a given color that appears more times for product x than another color. For example, if product x has 2 colors (black and white) and mostly the black color was viewed more by users, then black has a higher score than white.\n",
    "    - Another factor that was included in the equation is time decay factor, where we give more importance to a product that has been viewed several times in on day by a given user than a product that has been viewed several times but across several days that are far apart by the same user. The time decay factor was calculated by followaing the log approach, in order to give importance to reecency of the view date. For instance if user x has viewed product y today and yesterday the value of the decay factor won't be the same as when user x viewed product y today and 3 months ago.\n",
    "    - The score equation is as follows: ( 1 * product views + 2 * cart adds + 1.92 * color ) * time decay factor.\n",
    "3. Transforming the mcvisid and model id into numerical values by implementing stringindexer in order to pass them when creating ALS models.\n",
    "4. Splitting the data, this process was done by deciding to take the recent interaction made by the user and store it in the test set and the rest in the train set. However, if a user only made one or a few number of interactions it doesn't make sense to take the last interaction, therefore I have checked what would be a reasonable threshold that I can implement in order to get a decent test set size. Taking the users who have made 4 or more interactions as my 'concentrated datapoints' where I take the last interaction they made and store it in the test set. This results in around a 100k records in the test set\n",
    "5. Next part is tricky and can distort the model if not implemented correctly. Normalization, this phase has to be implemented after the train/test spllit in order to avoid data leakage, by this I mean passing information from the train to the test set. This is unlike the stringindexer part as this process is required to be done before the splitting in order not to distort the dataset.\n",
    "6. Model fitting, in this stage we try different hyperparameters such as ranks, maxIter and regParams, finding the best model will show us what is the right combination of hyperparameters that resulted in a high accuracy. In total we're trying out 12 models\n",
    "7. Model evaluation, in this stage we start evaluation each model on the test set. This is done by first generating recommendations for each model, then evaluating these recommendations using the original value in the test set. The evaluation metric that has been used is precision@k, where it shows us on average how many of the models recommeded are related to the user's preference\n",
    "8. Using the best model we try to do some numeric/categorical visualizations, where I am interested in seeing if the last product the user has viewed gets products recommended to it. (REPARTO)\n",
    "9. Few discussion points that can implemented later on. Cross validation can implemented in order to get higher accuracy, also few tweaks in the weights might help get better scores. I can also try to see if I can introduce another variable into the score/rating equation, maybe the date variable can be broken down and used if the dataset contains all of the months in the year. This can introduce the seasonality concept, where certain products get viewed during a specific period of the year. Another point that can be done is trying more than 12 models, by increasing the combination of hyperparameters. Due to the cluset being terminanted because of being idle for a given period, this was hard to implement unfortunately. Also changing the threshold of the train/test split might lead to a better accuracy score, however this is highly unlikely as the dataset is already very large and 100k records for a test set is very good actually.\n",
    "10. This project can still have some work done on it, but it's a starting point. Item-based recommendation system can also be implemented, for instance, cosine similarity can be implemented in order to measure the similarity between products. Clustering techniques can be a possibility as well to be implemented after calculating the similarity, to check the type of products that are grouped together based on their similarity scores."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "034df4fe-0027-49e4-9348-bbc294ea8b75",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 1. Load Data & Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd1301af-b2ae-4f44-a298-c7c8d6e93b56",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import StringIndexerModel\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.sql.functions import stddev, mean, col\n",
    "from pyspark.sql.functions import max\n",
    "from pyspark.sql.functions import min\n",
    "from pyspark.mllib.recommendation import Rating\n",
    "from pyspark.ml.evaluation import RankingEvaluator\n",
    "from pyspark.sql.functions import desc, row_number\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.functions import exp, sum, avg, when, from_unixtime, unix_timestamp, datediff, log1p, abs, udf, countDistinct,  count, explode, collect_list, array, struct, expr\n",
    "from pyspark.ml.recommendation import ALSModel\n",
    "import os\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46fe81e6-83df-4c59-8daa-80f7154d8657",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# set base path\n",
    "BASE_PATH_RECOM = '/FileStore/tables/1_recommendation/'\n",
    "# ls the files in the base path\n",
    "dbutils.fs.ls(BASE_PATH_RECOM)\n",
    "\n",
    "# load web navigation\n",
    "df_web = (\n",
    "  spark.read.format('csv')\n",
    "  .option('header', 'true')\n",
    "  .option('sep', ',')\n",
    "  .load(BASE_PATH_RECOM + 'web_navigations.csv')\n",
    ")\n",
    "\n",
    "# load web navigation\n",
    "df_sku = (\n",
    "  spark.read.format('csv')\n",
    "  .option('header', 'true')\n",
    "  .option('sep', ',')\n",
    "  .load(BASE_PATH_RECOM + 'sku_details.csv')\n",
    ")\n",
    "\n",
    "df = (\n",
    "    df_web\n",
    "    .where(\"ADOBE_SKU is not NULL\")\n",
    "    .join(df_sku, on = 'ADOBE_SKU', how = 'left')   \n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "589d4232-ca5d-499b-9147-60673b19a645",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "574cc734-a40e-43fb-9859-ee83272f2789",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def Product_Key_Split (df):\n",
    "    split_col=split(df['ADOBE_SKU'], '_')\n",
    "    df = df.withColumn('Model', split_col.getItem(0)).withColumn('Material', split_col.getItem(1)).withColumn('Color', split_col.getItem(2))\n",
    "    print(\"Product_Key_Split Completed\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cc3195d-0ba9-45ef-a222-12a1e68a28b6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def weights_calculation(df):\n",
    "    # grouping by user and product and calculate the total number of views and purchases\n",
    "    grouped_cart_df = (\n",
    "        df\n",
    "        .groupBy('mcvisid', 'Model')\n",
    "        .agg(\n",
    "            sum('Product_Views_custom').alias('total_views'),\n",
    "            sum('Cart_Adds').alias('total_cart_adds')\n",
    "        )\n",
    "        .filter(col('total_cart_adds') >= 1)\n",
    "    )\n",
    "    \n",
    "    # calculating the average number of views per purchase for each user\n",
    "    result_cart_df = (\n",
    "        grouped_cart_df\n",
    "        .groupBy('mcvisid')\n",
    "        .agg(avg(col('total_views') / col('total_cart_adds')).alias('average_views_per_cart_adds'))\n",
    "        .filter(col('average_views_per_cart_adds').isNotNull())\n",
    "    )\n",
    "    \n",
    "    df_filtered = df.filter(sorted_df['Product_Views_custom'] == 1)\n",
    "    # Calculating the distinct colors viewed per user\n",
    "    distinct_colors_per_user = df_filtered.groupBy('mcvisid').agg(countDistinct('Color').alias('distinct_colors'))\n",
    "\n",
    "    # Calculating the average distinct colors viewed per user\n",
    "    average_distinct_views = distinct_colors_per_user.select(avg('distinct_colors').alias('average_distinct_views'))\n",
    "    \n",
    "    print(\"weights_calculation Completed\")\n",
    "    return result_cart_df, average_distinct_views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1161350d-8773-4817-8bc6-c5d0e2bd585a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def color_score_calculation (view_name, df):\n",
    "    df_color_agg = spark.sql('''\n",
    "        SELECT Model, Color, (Total_Views + Total_Cart_Adds) as Color_Score\n",
    "        FROM \n",
    "         (\n",
    "              SELECT Model, Color, SUM(Product_Views_custom) as Total_Views, SUM(2*Cart_Adds) as Total_Cart_Adds \n",
    "              FROM GeneralTable \n",
    "              GROUP BY Model, Color\n",
    "         )\n",
    "\n",
    "    ''')\n",
    "    \n",
    "    df_total_interactions = spark.sql('''\n",
    "        SELECT Model, (Total_Views + Total_Cart_Adds) as Score\n",
    "        FROM \n",
    "         (\n",
    "              SELECT Model, SUM(Product_Views_custom) as Total_Views, SUM(2*Cart_Adds) as Total_Cart_Adds \n",
    "              FROM GeneralTable \n",
    "              GROUP BY Model\n",
    "         )\n",
    "\n",
    "    ''')\n",
    "    \n",
    "    # Calculating the score for each combination of product ID, color, and material\n",
    "    df_partial_scores = df_color_agg.join(df_total_interactions, \"Model\").withColumn(\n",
    "        \"Final_Color_Score\", col(\"Color_Score\") / col(\"Score\")\n",
    "    )\n",
    "    \n",
    "    df = df.join(df_partial_scores.select(\"Model\", \"Final_Color_Score\"), on = \"Model\")\n",
    "    df = df.select(\"mcvisid\",\"date\", \"Model\", \"Color\", \"REPARTO\",\"Product_Views_Custom\", \"Cart_Adds\",\"Final_Color_Score\")\n",
    "    \n",
    "    print(\"color_score_calculation Completed\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b9f90b1-b235-4a10-8fe5-929dd5173445",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def max_date(df):\n",
    "    # Calculating the maximum date for each user-product combination\n",
    "    max_date_df = df.groupBy('mcvisid', 'Model').agg({'date': 'max'})\\\n",
    "                   .withColumnRenamed('max(date)', 'last_view_date')\n",
    "\n",
    "    # Joining the max_date_df with the original df\n",
    "    df_with_max_date = df.join(max_date_df, ['mcvisid', 'Model'])\n",
    "    \n",
    "    print(\"max_date Completed\")\n",
    "    return df_with_max_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ddf206a-9e19-457f-9184-901dfd68bec3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def Score_calculation(df, CA_W, Color_W):\n",
    "    half_life_days = 7\n",
    "    # Calculating the decay factor based on the last view date\n",
    "    decay_factor = (\n",
    "        when(datediff(col('date'), col('last_view_date')) == 0, 1)\n",
    "        .otherwise(1 / log1p(1 + (abs(datediff(col('date'), col('last_view_date'))) / half_life_days)))\n",
    "    )\n",
    "    \n",
    "    df_with_score = df.withColumn(\"Total_score\", (col('Product_Views_custom') + CA_W * col('Cart_Adds') + Color_W * col(\"Final_Color_Score\")) * decay_factor)\n",
    "    score_df = df_with_score.groupBy('mcvisid', 'Model', 'date').agg(sum('Total_score').alias('Score'))\n",
    "    \n",
    "    lower_quartile = score_df.approxQuantile(\"Score\", [0.25], 0.01)[0]\n",
    "    upper_quartile = score_df.approxQuantile(\"Score\", [0.75], 0.01)[0]\n",
    "    iqr = upper_quartile - lower_quartile\n",
    "\n",
    "    # Calculating lower and upper bounds\n",
    "    lower_bound = lower_quartile - 1.5 * iqr\n",
    "    upper_bound = upper_quartile + 1.5 * iqr\n",
    "    print(\"Lower bound:\", lower_bound)\n",
    "    print(\"Upper bound:\", upper_bound)\n",
    "    \n",
    "    # Seting scores below lower bound to lower bound, and scores above upper bound to upper bound\n",
    "    score_adj_df = score_df.withColumn('Score', when(col('Score') < lower_bound, lower_bound).otherwise(col('Score')))\n",
    "    score_adj_df = score_df.withColumn('Score', when(col('Score') > upper_bound, upper_bound).otherwise(col('Score')))\n",
    "    \n",
    "    print(\"Score_calculation Completed\")\n",
    "    return score_adj_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "208881a9-7212-468b-9f96-5423a345e320",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = Product_Key_Split(df)\n",
    "sorted_df = df.orderBy(['mcvisid', 'date'])\n",
    "views_per_cart_df, avg_distinct_color_views_score = weights_calculation(sorted_df)\n",
    "value_list = avg_distinct_color_views_score.collect()\n",
    "# Accessing the value from the list\n",
    "avg_dist_color_views = value_list[0][0]\n",
    "print(avg_dist_color_views)\n",
    "display(views_per_cart_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1803ee0c-de98-4719-b203-ddab12512bb1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(sorted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f901108-6e06-4693-a806-a0b1edb27da5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Cart_Adds_Weight = 2\n",
    "Color_Weight = 1.92\n",
    "sorted_df.createOrReplaceTempView('GeneralTable')\n",
    "sorted_df = color_score_calculation('GeneralTable', sorted_df)\n",
    "max_date_df = max_date(sorted_df)\n",
    "adj_df =  Score_calculation(max_date_df, Cart_Adds_Weight, Color_Weight)\n",
    "display(adj_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f622ea13-04f7-40d8-ba24-b9e069c1d2f7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 3. String To Index (Products & Visitors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "074fce11-8890-4a11-9640-07209c22466b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def StringToIndex(df, val, val_date):\n",
    "    indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(df) for column in df.columns if column not in {val, val_date}]\n",
    "    pipeline = Pipeline(stages=indexers)\n",
    "    pipeline_model = pipeline.fit(df)\n",
    "    df_indexed = pipeline_model.transform(df)\n",
    "    string_indexer_models = [stage for stage in pipeline_model.stages if isinstance(stage, StringIndexerModel)]\n",
    "    print(\"StringToIndex completed\")\n",
    "    return df_indexed, string_indexer_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cad43be5-ba6f-47fd-b875-b1b23115e3ca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StringToIndex completed\n"
     ]
    }
   ],
   "source": [
    "df_idx, string_idx_models = StringToIndex(adj_df, 'Score', 'date')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "710ad956-3f11-488d-bc9c-2652d9999059",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 4. Splitting The Data Into Train & Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9d94af6-1e17-41dc-a663-c3c3582e0b23",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def interactions_per_user(df, val):\n",
    "    # grouping by user_id and count number of interactions\n",
    "    user_counts = df.groupBy('mcvisid').agg(count('*').alias('interactions'))\n",
    "    # filtering out users with less than 5 interactions\n",
    "    user_counts = user_counts.filter(col('interactions') >= val)\n",
    "    \n",
    "    record_count = user_counts.count()\n",
    "    print(\"Total record count:\", record_count)\n",
    "    return user_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f774811-4a3a-4fab-adc9-8e5f09813b86",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def split_data(df, val):\n",
    "    # joining back to original data to get latest interaction for each user\n",
    "    latest_interactions = df.join(val, on='mcvisid') \\\n",
    "                            .orderBy(['mcvisid', 'date'], ascending=[True, False]) \\\n",
    "                            .withColumn('rank', row_number().over(Window.partitionBy('mcvisid').orderBy(desc('date')))) \\\n",
    "                            .filter(col('rank') == 1) \\\n",
    "                            .select('mcvisid', 'Model', 'mcvisid_index', 'Model_index','Score', 'date')\n",
    "\n",
    "    # spliting data into train and test sets\n",
    "    train = df.join(latest_interactions, on=['mcvisid', 'Model', 'mcvisid_index', 'Model_index','Score', 'date'], how='left_anti')\n",
    "    test = latest_interactions.select('mcvisid', 'Model', 'mcvisid_index', 'Model_index', 'Score', 'date')\n",
    "    \n",
    "    print(\"split_data completed\")\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65286ed2-d13d-47e9-911a-71b51dcde129",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def set_size(df, df_train, df_test):\n",
    "    df_size1 = df.count()\n",
    "    print(\"Size of the entire dataset:\", df_size1)\n",
    "    df_size2 = df_train.count()\n",
    "    print(\"Size of the train set:\", df_size2)\n",
    "    df_size3 = df_test.count()\n",
    "    print(\"Size of the test set:\", df_size3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfdea2a2-6a20-4d40-a9f4-e78add1a5fdc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total record count: 109364\n",
      "split_data completed\n"
     ]
    }
   ],
   "source": [
    "nb_of_users = interactions_per_user(df_idx, 4)\n",
    "train_df, test_df = split_data(df_idx, nb_of_users)\n",
    "set_size(df_idx, train_df, test_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f16ab762-4ad5-4e06-8ae5-4cd3fd8b3020",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 5. Normalizing The Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fefb62fc-f706-4fd7-9390-fe8a856f8eac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def normalize_score(df):\n",
    "    min_score = df.agg({\"score\": \"min\"}).collect()[0][0]\n",
    "    max_score = df.agg({\"score\": \"max\"}).collect()[0][0]\n",
    "\n",
    "    # Defining the UDF for normalization\n",
    "    normalize_udf = udf(lambda x: (x - min_score) / (max_score - min_score))\n",
    "    score_normalized_df = df.withColumn(\"Score_Normalized\", normalize_udf(col(\"Score\")))\n",
    "    \n",
    "    print(\"normalize_score completed\")\n",
    "    return score_normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5348af71-6cc1-4fb1-afea-56f596a62d1d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalize_score completed\n",
      "normalize_score completed\n"
     ]
    }
   ],
   "source": [
    "train_norm_df = normalize_score(train_df)\n",
    "test_norm_df = normalize_score(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c3bff39-e053-4c97-9d02-6d7a565b54a8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_norm_df = train_norm_df.withColumn(\"Score_Normalized\", train_norm_df[\"Score_Normalized\"].cast(FloatType()))\n",
    "test_norm_df = test_norm_df.withColumn(\"Score_Normalized\", test_norm_df[\"Score_Normalized\"].cast(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1df87dbf-b9f3-442a-9ffe-fffcc15c074a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_norm_df.write.parquet(BASE_PATH_RECOM + \"/train_norm_dfII.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed5d99f9-471b-4c24-b3fd-b2ec6c0633ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_norm_df.write.parquet(BASE_PATH_RECOM + \"/test_norm_df.parquet\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40cd0bf1-1f0c-47ff-ae81-3fc81679ecf7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 6. ALS Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9854175-2bd2-4816-92c7-efa6ac22a32e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "models_folder = 'models_Trialiii_ALS'\n",
    "model_path = f\"{BASE_PATH_RECOM}/{models_folder}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ed23120-e8e7-4df8-9276-3f7198c6c7c4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_norm_df = spark.read.parquet(\"/FileStore/tables/1_recommendation/train_norm_dfII.parquet/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0482e06-8828-48ab-9079-ae39baa7507f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def als_models(ranks, iterations, regularization, u_col, i_col, r_col):\n",
    "    als_list = []\n",
    "    idx = 0\n",
    "    for k in ranks:\n",
    "        for itr in iterations:\n",
    "            for reg_p in regularization:\n",
    "                    model_name = f\"model_{idx}\"\n",
    "                    idx = idx + 1\n",
    "                    als_model = (ALS(maxIter=itr,regParam = reg_p, rank = k, implicitPrefs = True, userCol= u_col, \n",
    "                                     itemCol= i_col, ratingCol = r_col, coldStartStrategy=\"drop\",nonnegative=True))\n",
    "                    als_list.append((model_name, als_model))    \n",
    "    print(\"list_of_models_complete\")\n",
    "    return als_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e838595-154a-44d1-8d1c-ac2b71430887",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def model_fit(df_train, models):\n",
    "    for name, model in models:\n",
    "        fitted = model.fit(df_train)\n",
    "        fitted.save(f\"{model_path}/{name}\")\n",
    "        print(name, \" complete\")\n",
    "    print(\"model_fit complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e9ac76f-52c2-464f-a299-29fd89ba1cea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ranks = [3, 5, 10]\n",
    "maxIters = [10, 20]\n",
    "regParams = [0.05, 0.1]\n",
    "train_norm_df.cache()\n",
    "models = als_models(ranks, maxIters, regParams, \"mcvisid_index\", \"Model_index\", \"Score_Normalized\")\n",
    "model_fit(train_norm_df, models)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f86125cd-86cd-48eb-84a8-e4e6f30626a3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 7. ALS Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3b9c32b-9cee-4c8c-aa61-f4938427d8e0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_norm_df = spark.read.parquet(\"/FileStore/tables/1_recommendation/test_norm_df.parquet/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7d0beb8-fa74-43bf-a753-91d8983c44e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def load_model(path, val):\n",
    "    loaded_models = []\n",
    "    for i in range(val):\n",
    "        model_path_with_number = f\"{path}model_{i}\"\n",
    "        loaded_models.append(ALSModel.load(model_path_with_number))\n",
    "    print(\"load_model complete\")\n",
    "    return loaded_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7a74eee-c8d5-45c8-a7bf-dd249c163c15",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_model complete\n"
     ]
    }
   ],
   "source": [
    "models_path = '/FileStore/tables/1_recommendation/models_Trialiii_ALS/'\n",
    "models = load_model(models_path, 12) # 12 is the number of models created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da4dc023-957c-4edf-b7b2-be97752b6bc9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def generate_recommendation(model, test_df, val):\n",
    "    k = val\n",
    "    top_k_recommendations = model.recommendForUserSubset(test_df, k)\n",
    "    # Sorting the recommendations in descending order of similarity\n",
    "    sorted_recommendations = top_k_recommendations.withColumn(\"sorted_recommendations\", F.expr(\"sort_array(recommendations, false)\"))\n",
    "    print(\"generate_recommendation complete\")\n",
    "    return sorted_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d980ba9-eb76-4120-84cc-7bfd8e4fcd44",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def calculate_precision_at_k(test_df, recommendations, k):\n",
    "    ground_truth = test_df.select('mcvisid_index', 'Model_index')\n",
    "    # Joining recommendations and ground truth on user_id\n",
    "    joined_df = recommendations.join(ground_truth, 'mcvisid_index')\n",
    "    # Calculating precision@k\n",
    "    precision_at_k = joined_df.withColumn(\n",
    "        'intersection',\n",
    "        expr(f'array_intersect(sorted_recommendations.Model_index, array({\",\".join(str(i) for i in range(k))}))')\n",
    "    ).withColumn(\n",
    "        'precision_at_k',\n",
    "        expr(f'size(intersection) / {k}')\n",
    "    ).agg({'precision_at_k': 'mean'}).first()[0]\n",
    "    print(\"calculate_precision_at_k complete\")\n",
    "    return precision_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db50246f-c2fd-47e7-98fd-dcbb6eb566c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_recommendation complete\n",
      "calculate_precision_at_k complete\n",
      "model_0\n",
      "Precision@10: 0.5883\n",
      "generate_recommendation complete\n",
      "calculate_precision_at_k complete\n",
      "model_1\n",
      "Precision@10: 0.6080\n",
      "generate_recommendation complete\n",
      "calculate_precision_at_k complete\n",
      "model_2\n",
      "Precision@10: 0.4838\n",
      "generate_recommendation complete\n",
      "calculate_precision_at_k complete\n",
      "model_3\n",
      "Precision@10: 0.5215\n",
      "generate_recommendation complete\n",
      "calculate_precision_at_k complete\n",
      "model_4\n",
      "Precision@10: 0.4688\n",
      "generate_recommendation complete\n",
      "calculate_precision_at_k complete\n",
      "model_5\n",
      "Precision@10: 0.5134\n",
      "generate_recommendation complete\n",
      "calculate_precision_at_k complete\n",
      "model_6\n",
      "Precision@10: 0.3607\n",
      "generate_recommendation complete\n",
      "calculate_precision_at_k complete\n",
      "model_7\n",
      "Precision@10: 0.4176\n",
      "generate_recommendation complete\n",
      "calculate_precision_at_k complete\n",
      "model_8\n",
      "Precision@10: 0.2560\n",
      "generate_recommendation complete\n",
      "calculate_precision_at_k complete\n",
      "model_9\n",
      "Precision@10: 0.2507\n",
      "generate_recommendation complete\n",
      "calculate_precision_at_k complete\n",
      "model_10\n",
      "Precision@10: 0.2104\n",
      "generate_recommendation complete\n",
      "calculate_precision_at_k complete\n",
      "model_11\n",
      "Precision@10: 0.2287\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "i = 0\n",
    "for model in models:\n",
    "    recommendations_df = generate_recommendation(model, test_norm_df, k)\n",
    "    p_at_k = calculate_precision_at_k(test_norm_df, recommendations_df, k)\n",
    "    print(f\"model_{i}\")\n",
    "    print(f\"Precision@{k}: {p_at_k:.4f}\")\n",
    "    i = i+1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2a9213f0-db88-447a-bfd9-605fd04b814d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 8. Vieweing Some Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db8e3e2e-5152-4f88-a811-ca86e7a4fac3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def recommendation_evaluation(u_rec_list, test_df, string_indexer_models):\n",
    "        rec_alias = u_rec_list.alias(\"rec\")\n",
    "        test_alias = test_df.alias(\"test\")\n",
    "        recommendations_with_mcvisid = rec_alias.join(test_alias, col(\"rec.mcvisid_index\") == col(\"test.mcvisid_index\"), \"left\")\n",
    "        # Selecting relevant columns and renaming them\n",
    "        recommendations_with_mcvisid = recommendations_with_mcvisid.select(col(\"test.mcvisid\").alias(\"mcvisid\"), col(\"rec.sorted_recommendations\"))\n",
    "\n",
    "        # Retrieving values from the recommendations column\n",
    "        rows = recommendations_with_mcvisid.collect()\n",
    "        x = 0\n",
    "        print(\"mcvisid |\", \"| recommendations\")\n",
    "        for row in rows:\n",
    "            mcvisid = row[\"mcvisid\"]\n",
    "            recommendations = row[\"sorted_recommendations\"]\n",
    "            original_values = [string_idx_models[1].labels[int(rec[0])] for rec in recommendations]\n",
    "            print(mcvisid, original_values)\n",
    "            x = x+1\n",
    "            if (x>10):\n",
    "                break\n",
    "        print(\"---------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d566ea13-bc3b-4ea6-bedb-7f93a68d1d88",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Final_recommendations_df = generate_recommendation(models[1], test_norm_df, k)\n",
    "recommendation_evaluation(Final_recommendations_df, test_norm_df, string_idx_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8164b903-e553-4a7b-a40d-6e30ed805712",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "specific_id = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "\n",
    "filtered_df = test_norm_df.filter(test_norm_df['mcvisid'] == specific_id)\n",
    "\n",
    "filtered_df.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3408364019472980,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "ALS_Recommendation_System_PRADA_Lab",
   "notebookOrigID": 2832977809701593,
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
